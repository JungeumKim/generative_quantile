{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49440dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import sys\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677c14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/kim2712/Desktop/research/generative_quantile/generative_qunatile\")\n",
    "from _nets import wgan2\n",
    "from _data.gaussian_conjugate import forward_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9131527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nABC = 1000#00\n",
    "N_y=2\n",
    "theta_dim=2\n",
    "\n",
    "HPARAM = {\"nu\":25, \"sigma0_sq\":1, \"mu0\":0,\"kappa\":2}\n",
    "theta_seq, X_seq = forward_sampler(n = N_y, \n",
    "                                batch_size=nABC,\n",
    "                                device=\"cuda\",\n",
    "                                h_param=HPARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4862e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_names=[\"theta\"+str(i) for i in range(1,theta_dim+1)]\n",
    "X_names=[\"X\"+str(i) for i in range(1,N_y+1)]\n",
    "\n",
    "df=pd.DataFrame(data=np.concatenate((theta_seq,X_seq),axis=-1),\n",
    "               columns=(theta_names+X_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ad1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = None #\"gauss_\"+str(n_test)+\"_nu/cp.ckpt\"\n",
    "checkpoint_dir = \"./\"\n",
    "save_checkpoint = F\"{checkpoint_dir}/checkpoint.ck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3349466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "pathlib.Path(checkpoint_dir).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b372609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "settings: {'optimizer': <class 'torch.optim.adam.Adam'>, 'activation': 'relu', 'critic_d_hidden': [128, 128, 128], 'critic_dropout': 0, 'critic_steps': 15, 'critic_lr': 0.001, 'critic_gp_factor': 5, 'discriminator_d_hidden': [128, 128, 128], 'discriminator_dropout': 0.1, 'discriminator_steps': 1, 'discriminator_lr': 0.0001, 'generator_d_hidden': [128, 128, 128], 'generator_dropout': 0.1, 'generator_lr': 0.001, 'generator_d_noise': 2, 'generator_optimizer': 'optimizer', 'big_Z': False, 'max_epochs': 2020, 'batch_size': 1280, 'test_set_size': 16, 'load_checkpoint': None, 'save_checkpoint': './/checkpoint.ck', 'save_every': 10, 'print_every': 10, 'history_path': None, 'device': 'cuda'}\n"
     ]
    }
   ],
   "source": [
    "data_wrapper= wgan2.DataWrapper(df, continuous_vars=theta_names, context_vars=X_names)\n",
    "\n",
    "spec=wgan2.Specifications(data_wrapper, batch_size=1280, max_epochs=2020, \n",
    "                          critic_lr=1e-3, generator_lr=1e-3,\n",
    "                         print_every=10,device = \"cuda\",\n",
    "                        #load_checkpoint=None,#checkpoint_dir,\n",
    "                          save_checkpoint = save_checkpoint,\n",
    "                        save_every=10)\n",
    "\n",
    "generator=wgan2.Generator(spec)\n",
    "critic=wgan2.Critic(spec)\n",
    "thetas, Xs = data_wrapper.preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a8104b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | step 2 | WD_test 0.06 | WD_train 0.01 | sec passed 3 |\n",
      "epoch 10 | step 12 | WD_test 0.62 | WD_train 0.42 | sec passed 0 |\n",
      "epoch 20 | step 22 | WD_test 1.04 | WD_train 0.9 | sec passed 0 |\n",
      "epoch 30 | step 32 | WD_test 1.06 | WD_train 0.95 | sec passed 0 |\n",
      "epoch 40 | step 42 | WD_test 1.11 | WD_train 1.03 | sec passed 0 |\n",
      "epoch 50 | step 52 | WD_test 1.13 | WD_train 1.04 | sec passed 0 |\n",
      "epoch 60 | step 62 | WD_test 1.12 | WD_train 1.06 | sec passed 0 |\n",
      "epoch 70 | step 72 | WD_test 1.15 | WD_train 1.07 | sec passed 0 |\n",
      "epoch 80 | step 82 | WD_test 1.12 | WD_train 1.06 | sec passed 0 |\n",
      "epoch 90 | step 92 | WD_test 1.08 | WD_train 1.03 | sec passed 0 |\n",
      "epoch 100 | step 102 | WD_test 1.11 | WD_train 1.04 | sec passed 0 |\n",
      "epoch 110 | step 112 | WD_test 1.07 | WD_train 1.02 | sec passed 0 |\n",
      "epoch 120 | step 122 | WD_test 1.03 | WD_train 0.97 | sec passed 0 |\n",
      "epoch 130 | step 132 | WD_test 0.97 | WD_train 0.98 | sec passed 0 |\n",
      "epoch 140 | step 142 | WD_test 1.0 | WD_train 0.93 | sec passed 0 |\n",
      "epoch 150 | step 152 | WD_test 0.99 | WD_train 0.88 | sec passed 0 |\n",
      "epoch 160 | step 162 | WD_test 0.94 | WD_train 0.89 | sec passed 0 |\n",
      "epoch 170 | step 172 | WD_test 0.82 | WD_train 0.83 | sec passed 0 |\n",
      "epoch 180 | step 182 | WD_test 0.79 | WD_train 0.77 | sec passed 0 |\n",
      "epoch 190 | step 192 | WD_test 0.92 | WD_train 0.79 | sec passed 0 |\n",
      "epoch 200 | step 202 | WD_test 0.79 | WD_train 0.73 | sec passed 1 |\n",
      "epoch 210 | step 212 | WD_test 0.76 | WD_train 0.67 | sec passed 0 |\n",
      "epoch 220 | step 222 | WD_test 0.78 | WD_train 0.7 | sec passed 0 |\n",
      "epoch 230 | step 232 | WD_test 0.69 | WD_train 0.63 | sec passed 0 |\n",
      "epoch 240 | step 242 | WD_test 0.59 | WD_train 0.59 | sec passed 0 |\n",
      "epoch 250 | step 252 | WD_test 0.68 | WD_train 0.63 | sec passed 0 |\n",
      "epoch 260 | step 262 | WD_test 0.63 | WD_train 0.61 | sec passed 0 |\n",
      "epoch 270 | step 272 | WD_test 0.53 | WD_train 0.61 | sec passed 0 |\n",
      "epoch 280 | step 282 | WD_test 0.68 | WD_train 0.62 | sec passed 0 |\n",
      "epoch 290 | step 292 | WD_test 0.66 | WD_train 0.62 | sec passed 0 |\n",
      "epoch 300 | step 302 | WD_test 0.63 | WD_train 0.61 | sec passed 0 |\n",
      "epoch 310 | step 312 | WD_test 0.62 | WD_train 0.61 | sec passed 0 |\n",
      "epoch 320 | step 322 | WD_test 0.65 | WD_train 0.58 | sec passed 0 |\n",
      "epoch 330 | step 332 | WD_test 0.68 | WD_train 0.55 | sec passed 0 |\n",
      "epoch 340 | step 342 | WD_test 0.73 | WD_train 0.51 | sec passed 0 |\n",
      "epoch 350 | step 352 | WD_test 0.58 | WD_train 0.44 | sec passed 0 |\n",
      "epoch 360 | step 362 | WD_test 0.61 | WD_train 0.4 | sec passed 0 |\n",
      "epoch 370 | step 372 | WD_test 0.53 | WD_train 0.4 | sec passed 0 |\n",
      "epoch 380 | step 382 | WD_test 0.59 | WD_train 0.32 | sec passed 0 |\n",
      "epoch 390 | step 392 | WD_test 0.38 | WD_train 0.27 | sec passed 0 |\n",
      "epoch 400 | step 402 | WD_test 0.45 | WD_train 0.27 | sec passed 0 |\n",
      "epoch 410 | step 412 | WD_test 0.33 | WD_train 0.18 | sec passed 1 |\n",
      "epoch 420 | step 422 | WD_test 0.45 | WD_train 0.17 | sec passed 0 |\n",
      "epoch 430 | step 432 | WD_test 0.12 | WD_train 0.17 | sec passed 0 |\n",
      "epoch 440 | step 442 | WD_test 0.08 | WD_train 0.17 | sec passed 0 |\n",
      "epoch 450 | step 452 | WD_test 0.32 | WD_train 0.2 | sec passed 0 |\n",
      "epoch 460 | step 462 | WD_test 0.33 | WD_train 0.25 | sec passed 0 |\n",
      "epoch 470 | step 472 | WD_test 0.09 | WD_train 0.26 | sec passed 0 |\n",
      "epoch 480 | step 482 | WD_test -0.05 | WD_train 0.23 | sec passed 0 |\n",
      "epoch 490 | step 492 | WD_test 0.09 | WD_train 0.23 | sec passed 0 |\n",
      "epoch 500 | step 502 | WD_test -0.03 | WD_train 0.26 | sec passed 0 |\n",
      "epoch 510 | step 512 | WD_test 0.02 | WD_train 0.21 | sec passed 0 |\n",
      "epoch 520 | step 522 | WD_test 0.36 | WD_train 0.29 | sec passed 0 |\n",
      "epoch 530 | step 532 | WD_test 0.7 | WD_train 0.3 | sec passed 0 |\n",
      "epoch 540 | step 542 | WD_test 0.7 | WD_train 0.29 | sec passed 0 |\n",
      "epoch 550 | step 552 | WD_test 0.86 | WD_train 0.3 | sec passed 0 |\n",
      "epoch 560 | step 562 | WD_test 0.58 | WD_train 0.29 | sec passed 0 |\n",
      "epoch 570 | step 572 | WD_test 0.6 | WD_train 0.23 | sec passed 0 |\n",
      "epoch 580 | step 582 | WD_test 0.52 | WD_train 0.28 | sec passed 0 |\n",
      "epoch 590 | step 592 | WD_test 0.5 | WD_train 0.28 | sec passed 0 |\n",
      "epoch 600 | step 602 | WD_test 0.54 | WD_train 0.29 | sec passed 0 |\n",
      "epoch 610 | step 612 | WD_test 0.35 | WD_train 0.3 | sec passed 0 |\n",
      "epoch 620 | step 622 | WD_test 0.29 | WD_train 0.31 | sec passed 0 |\n",
      "epoch 630 | step 632 | WD_test 0.24 | WD_train 0.25 | sec passed 0 |\n",
      "epoch 640 | step 642 | WD_test 0.1 | WD_train 0.27 | sec passed 0 |\n",
      "epoch 650 | step 652 | WD_test 0.2 | WD_train 0.23 | sec passed 0 |\n",
      "epoch 660 | step 662 | WD_test 0.19 | WD_train 0.18 | sec passed 0 |\n",
      "epoch 670 | step 672 | WD_test 0.15 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 680 | step 682 | WD_test 0.32 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 690 | step 692 | WD_test 0.11 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 700 | step 702 | WD_test 0.28 | WD_train 0.2 | sec passed 0 |\n",
      "epoch 710 | step 712 | WD_test 0.44 | WD_train 0.23 | sec passed 0 |\n",
      "epoch 720 | step 722 | WD_test 0.59 | WD_train 0.22 | sec passed 0 |\n",
      "epoch 730 | step 732 | WD_test 0.38 | WD_train 0.23 | sec passed 0 |\n",
      "epoch 740 | step 742 | WD_test 0.21 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 750 | step 752 | WD_test -0.2 | WD_train 0.13 | sec passed 0 |\n",
      "epoch 760 | step 762 | WD_test 0.04 | WD_train 0.13 | sec passed 0 |\n",
      "epoch 770 | step 772 | WD_test 0.07 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 780 | step 782 | WD_test 0.08 | WD_train 0.17 | sec passed 0 |\n",
      "epoch 790 | step 792 | WD_test -0.39 | WD_train 0.21 | sec passed 0 |\n",
      "epoch 800 | step 802 | WD_test -0.13 | WD_train 0.24 | sec passed 1 |\n",
      "epoch 810 | step 812 | WD_test -0.26 | WD_train 0.23 | sec passed 0 |\n",
      "epoch 820 | step 822 | WD_test -0.05 | WD_train 0.27 | sec passed 0 |\n",
      "epoch 830 | step 832 | WD_test -0.06 | WD_train 0.2 | sec passed 0 |\n",
      "epoch 840 | step 842 | WD_test 0.2 | WD_train 0.15 | sec passed 0 |\n",
      "epoch 850 | step 852 | WD_test 0.08 | WD_train 0.13 | sec passed 0 |\n",
      "epoch 860 | step 862 | WD_test 0.31 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 870 | step 872 | WD_test 0.28 | WD_train 0.15 | sec passed 0 |\n",
      "epoch 880 | step 882 | WD_test 0.56 | WD_train 0.18 | sec passed 0 |\n",
      "epoch 890 | step 892 | WD_test 0.06 | WD_train 0.2 | sec passed 0 |\n",
      "epoch 900 | step 902 | WD_test 0.0 | WD_train 0.23 | sec passed 0 |\n",
      "epoch 910 | step 912 | WD_test 0.28 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 920 | step 922 | WD_test 0.32 | WD_train 0.2 | sec passed 0 |\n",
      "epoch 930 | step 932 | WD_test 0.13 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 940 | step 942 | WD_test 0.3 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 950 | step 952 | WD_test 0.18 | WD_train 0.12 | sec passed 0 |\n",
      "epoch 960 | step 962 | WD_test 0.18 | WD_train 0.05 | sec passed 0 |\n",
      "epoch 970 | step 972 | WD_test 0.23 | WD_train 0.08 | sec passed 0 |\n",
      "epoch 980 | step 982 | WD_test 0.09 | WD_train 0.14 | sec passed 0 |\n",
      "epoch 990 | step 992 | WD_test 0.17 | WD_train 0.15 | sec passed 0 |\n",
      "epoch 1000 | step 1002 | WD_test 0.14 | WD_train 0.2 | sec passed 0 |\n",
      "epoch 1010 | step 1012 | WD_test 0.27 | WD_train 0.21 | sec passed 0 |\n",
      "epoch 1020 | step 1022 | WD_test 0.17 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 1030 | step 1032 | WD_test 0.01 | WD_train 0.23 | sec passed 0 |\n",
      "epoch 1040 | step 1042 | WD_test -0.1 | WD_train 0.23 | sec passed 0 |\n",
      "epoch 1050 | step 1052 | WD_test 0.11 | WD_train 0.18 | sec passed 0 |\n",
      "epoch 1060 | step 1062 | WD_test 0.22 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 1070 | step 1072 | WD_test 0.09 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 1080 | step 1082 | WD_test 0.07 | WD_train 0.15 | sec passed 0 |\n",
      "epoch 1090 | step 1092 | WD_test 0.19 | WD_train 0.19 | sec passed 1 |\n",
      "epoch 1100 | step 1102 | WD_test 0.26 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 1110 | step 1112 | WD_test 0.35 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 1120 | step 1122 | WD_test 0.37 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 1130 | step 1132 | WD_test 0.24 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 1140 | step 1142 | WD_test 0.62 | WD_train 0.23 | sec passed 0 |\n",
      "epoch 1150 | step 1152 | WD_test 0.19 | WD_train 0.26 | sec passed 0 |\n",
      "epoch 1160 | step 1162 | WD_test 0.18 | WD_train 0.2 | sec passed 0 |\n",
      "epoch 1170 | step 1172 | WD_test 0.3 | WD_train 0.18 | sec passed 0 |\n",
      "epoch 1180 | step 1182 | WD_test 0.69 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 1190 | step 1192 | WD_test 0.15 | WD_train 0.16 | sec passed 0 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1200 | step 1202 | WD_test 0.5 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 1210 | step 1212 | WD_test 0.42 | WD_train 0.12 | sec passed 0 |\n",
      "epoch 1220 | step 1222 | WD_test 0.39 | WD_train 0.08 | sec passed 0 |\n",
      "epoch 1230 | step 1232 | WD_test 0.46 | WD_train 0.14 | sec passed 0 |\n",
      "epoch 1240 | step 1242 | WD_test 0.33 | WD_train 0.17 | sec passed 0 |\n",
      "epoch 1250 | step 1252 | WD_test 0.35 | WD_train 0.18 | sec passed 0 |\n",
      "epoch 1260 | step 1262 | WD_test 0.2 | WD_train 0.2 | sec passed 0 |\n",
      "epoch 1270 | step 1272 | WD_test 0.22 | WD_train 0.18 | sec passed 0 |\n",
      "epoch 1280 | step 1282 | WD_test 0.41 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 1290 | step 1292 | WD_test 0.05 | WD_train 0.14 | sec passed 0 |\n",
      "epoch 1300 | step 1302 | WD_test 0.49 | WD_train 0.17 | sec passed 0 |\n",
      "epoch 1310 | step 1312 | WD_test 0.07 | WD_train 0.12 | sec passed 0 |\n",
      "epoch 1320 | step 1322 | WD_test 0.28 | WD_train 0.12 | sec passed 0 |\n",
      "epoch 1330 | step 1332 | WD_test 0.07 | WD_train 0.15 | sec passed 0 |\n",
      "epoch 1340 | step 1342 | WD_test 0.17 | WD_train 0.17 | sec passed 0 |\n",
      "epoch 1350 | step 1352 | WD_test -0.27 | WD_train 0.15 | sec passed 1 |\n",
      "epoch 1360 | step 1362 | WD_test 0.02 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 1370 | step 1372 | WD_test -0.03 | WD_train 0.19 | sec passed 1 |\n",
      "epoch 1380 | step 1382 | WD_test -0.1 | WD_train 0.15 | sec passed 0 |\n",
      "epoch 1390 | step 1392 | WD_test 0.3 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 1400 | step 1402 | WD_test 0.08 | WD_train 0.21 | sec passed 0 |\n",
      "epoch 1410 | step 1412 | WD_test -0.08 | WD_train 0.17 | sec passed 0 |\n",
      "epoch 1420 | step 1422 | WD_test 0.2 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 1430 | step 1432 | WD_test 0.09 | WD_train 0.12 | sec passed 0 |\n",
      "epoch 1440 | step 1442 | WD_test 0.24 | WD_train 0.11 | sec passed 0 |\n",
      "epoch 1450 | step 1452 | WD_test 0.28 | WD_train 0.14 | sec passed 0 |\n",
      "epoch 1460 | step 1462 | WD_test 0.18 | WD_train 0.14 | sec passed 0 |\n",
      "epoch 1470 | step 1472 | WD_test 0.1 | WD_train 0.14 | sec passed 0 |\n",
      "epoch 1480 | step 1482 | WD_test -0.07 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 1490 | step 1492 | WD_test 0.09 | WD_train 0.2 | sec passed 0 |\n",
      "epoch 1500 | step 1502 | WD_test 0.02 | WD_train 0.21 | sec passed 0 |\n",
      "epoch 1510 | step 1512 | WD_test 0.22 | WD_train 0.23 | sec passed 0 |\n",
      "epoch 1520 | step 1522 | WD_test -0.2 | WD_train 0.17 | sec passed 0 |\n",
      "epoch 1530 | step 1532 | WD_test 0.15 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 1540 | step 1542 | WD_test -0.23 | WD_train 0.15 | sec passed 0 |\n",
      "epoch 1550 | step 1552 | WD_test 0.16 | WD_train 0.09 | sec passed 0 |\n",
      "epoch 1560 | step 1562 | WD_test 0.1 | WD_train 0.08 | sec passed 0 |\n",
      "epoch 1570 | step 1572 | WD_test 0.24 | WD_train 0.12 | sec passed 0 |\n",
      "epoch 1580 | step 1582 | WD_test 0.48 | WD_train 0.12 | sec passed 0 |\n",
      "epoch 1590 | step 1592 | WD_test 0.42 | WD_train 0.15 | sec passed 0 |\n",
      "epoch 1600 | step 1602 | WD_test 0.74 | WD_train 0.15 | sec passed 0 |\n",
      "epoch 1610 | step 1612 | WD_test 0.51 | WD_train 0.2 | sec passed 0 |\n",
      "epoch 1620 | step 1622 | WD_test 0.54 | WD_train 0.18 | sec passed 0 |\n",
      "epoch 1630 | step 1632 | WD_test 0.71 | WD_train 0.22 | sec passed 0 |\n",
      "epoch 1640 | step 1642 | WD_test 0.79 | WD_train 0.19 | sec passed 0 |\n",
      "epoch 1650 | step 1652 | WD_test 0.33 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 1660 | step 1662 | WD_test 0.37 | WD_train 0.13 | sec passed 0 |\n",
      "epoch 1670 | step 1672 | WD_test 0.1 | WD_train 0.07 | sec passed 0 |\n",
      "epoch 1680 | step 1682 | WD_test 0.11 | WD_train 0.1 | sec passed 0 |\n",
      "epoch 1690 | step 1692 | WD_test -0.01 | WD_train 0.15 | sec passed 0 |\n",
      "epoch 1700 | step 1702 | WD_test -0.01 | WD_train 0.18 | sec passed 0 |\n",
      "epoch 1710 | step 1712 | WD_test -0.05 | WD_train 0.22 | sec passed 0 |\n",
      "epoch 1720 | step 1722 | WD_test -0.1 | WD_train 0.18 | sec passed 0 |\n",
      "epoch 1730 | step 1732 | WD_test -0.15 | WD_train 0.17 | sec passed 0 |\n",
      "epoch 1740 | step 1742 | WD_test -0.07 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 1750 | step 1752 | WD_test 0.12 | WD_train 0.17 | sec passed 0 |\n",
      "epoch 1760 | step 1762 | WD_test 0.01 | WD_train 0.15 | sec passed 0 |\n",
      "epoch 1770 | step 1772 | WD_test -0.03 | WD_train 0.11 | sec passed 0 |\n",
      "epoch 1780 | step 1782 | WD_test -0.08 | WD_train 0.12 | sec passed 0 |\n",
      "epoch 1790 | step 1792 | WD_test 0.09 | WD_train 0.1 | sec passed 0 |\n",
      "epoch 1800 | step 1802 | WD_test 0.3 | WD_train 0.12 | sec passed 0 |\n",
      "epoch 1810 | step 1812 | WD_test 0.53 | WD_train 0.12 | sec passed 0 |\n",
      "epoch 1820 | step 1822 | WD_test 0.41 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 1830 | step 1832 | WD_test 0.48 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 1840 | step 1842 | WD_test 0.69 | WD_train 0.2 | sec passed 0 |\n",
      "epoch 1850 | step 1852 | WD_test 0.65 | WD_train 0.2 | sec passed 0 |\n",
      "epoch 1860 | step 1862 | WD_test 0.43 | WD_train 0.21 | sec passed 0 |\n",
      "epoch 1870 | step 1872 | WD_test 0.43 | WD_train 0.18 | sec passed 0 |\n",
      "epoch 1880 | step 1882 | WD_test 0.43 | WD_train 0.16 | sec passed 1 |\n",
      "epoch 1890 | step 1892 | WD_test 0.67 | WD_train 0.13 | sec passed 0 |\n",
      "epoch 1900 | step 1902 | WD_test 0.27 | WD_train 0.12 | sec passed 0 |\n",
      "epoch 1910 | step 1912 | WD_test 0.14 | WD_train 0.13 | sec passed 0 |\n",
      "epoch 1920 | step 1922 | WD_test 0.06 | WD_train 0.17 | sec passed 0 |\n",
      "epoch 1930 | step 1932 | WD_test 0.16 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 1940 | step 1942 | WD_test 0.19 | WD_train 0.15 | sec passed 0 |\n",
      "epoch 1950 | step 1952 | WD_test 0.11 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 1960 | step 1962 | WD_test 0.21 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 1970 | step 1972 | WD_test 0.16 | WD_train 0.17 | sec passed 0 |\n",
      "epoch 1980 | step 1982 | WD_test -0.03 | WD_train 0.13 | sec passed 0 |\n",
      "epoch 1990 | step 1992 | WD_test 0.14 | WD_train 0.15 | sec passed 0 |\n",
      "epoch 2000 | step 2002 | WD_test 0.1 | WD_train 0.16 | sec passed 0 |\n",
      "epoch 2010 | step 2012 | WD_test 0.21 | WD_train 0.12 | sec passed 0 |\n"
     ]
    }
   ],
   "source": [
    "wgan2.train(generator, critic, thetas, Xs, spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cf0c68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ck = torch.load(save_checkpoint)\n",
    "print(ck['epoch'])\n",
    "generator.load_state_dict(ck[\"generator_state_dict\"])\n",
    "#critic.load_state_dict(ck[\"critic_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4845e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeat=50000\n",
    "M=2.2\n",
    "X0=np.array([M,M]).reshape(1,-1)\n",
    "X0_tile=np.repeat(X0, repeats=[n_repeat],axis=0)\n",
    "Z0=np.random.normal(size=(n_repeat, 2))\n",
    "\n",
    "df0=pd.DataFrame(data=np.concatenate((Z0,X0_tile),axis=-1),columns=(theta_names+X_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6244eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta1</th>\n",
       "      <th>theta2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.078532</td>\n",
       "      <td>1.192933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.018022</td>\n",
       "      <td>1.076689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192513</td>\n",
       "      <td>0.748294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.230789</td>\n",
       "      <td>1.207675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.616087</td>\n",
       "      <td>1.492202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.789278</td>\n",
       "      <td>1.243984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.248442</td>\n",
       "      <td>1.364525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.842347</td>\n",
       "      <td>1.146536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.565942</td>\n",
       "      <td>0.767835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1.881925</td>\n",
       "      <td>1.473529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         theta1    theta2\n",
       "0      1.078532  1.192933\n",
       "1      1.018022  1.076689\n",
       "2      1.192513  0.748294\n",
       "3      1.230789  1.207675\n",
       "4      0.616087  1.492202\n",
       "...         ...       ...\n",
       "49995  0.789278  1.243984\n",
       "49996  0.248442  1.364525\n",
       "49997  0.842347  1.146536\n",
       "49998  0.565942  0.767835\n",
       "49999  1.881925  1.473529\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0_hat=data_wrapper.apply_generator(generator, df0)\n",
    "newtheta0_seq=theta0_hat[theta_names]\n",
    "newtheta0_seq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - Learning [learning/conda-2020.11-py38-gpu]",
   "language": "python",
   "name": "sys_learning38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
